# -*- coding: utf-8 -*-
"""export.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m9EL0LFBcDDQocGbYR0TCFmRtYXYnWlf
"""

import torch
from model import COVIDTweetClassifier

def export_to_onnx(model, dummy_input, onnx_file_path='covid_model.onnx'):
    model.eval()
    torch.onnx.export(
        model,
        dummy_input,
        onnx_file_path,
        input_names=['input_ids', 'attention_mask', 'features'],
        output_names=['output'],
        dynamic_axes={
            'input_ids': {0: 'batch_size'},
            'attention_mask': {0: 'batch_size'},
            'features': {0: 'batch_size'},
            'output': {0: 'batch_size'}
        },
        opset_version=14
    )
    print(f"Model exported to {onnx_file_path}")

if __name__ == '__main__':
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = COVIDTweetClassifier().to(device)
    state_dict = torch.load('covid_model.pth', map_location=device)
    state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}
    model.load_state_dict(state_dict)

    dummy_input_ids = torch.zeros(1, 128, dtype=torch.int64).to(device)
    dummy_attention_mask = torch.zeros(1, 128, dtype=torch.int64).to(device)
    dummy_features = torch.zeros(1, 3, dtype=torch.float32).to(device)

    export_to_onnx(model, (dummy_input_ids, dummy_attention_mask, dummy_features))
